{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout, Lambda\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import math\n",
    "import numpy as np\n",
    "from PIL import Image         \n",
    "import cv2                 \n",
    "import matplotlib.pyplot as plt\n",
    "from os import getcwd\n",
    "import csv\n",
    "# Fix error with TF and Keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_side_camera_images_flag = True\n",
    "\n",
    "X_data = []\n",
    "y_data = []\n",
    "\n",
    "correction = .175\n",
    "\n",
    "def load_images():    \n",
    "    with open('./record/driving_log.csv', 'r') as csvfile:\n",
    "        rows = csv.reader(csvfile)\n",
    "        for row in rows:\n",
    "            angle = float(row[3])\n",
    "            center_file_name = row[0].strip()\n",
    "            img_path = Image.open('./recording/' + center_file_name)\n",
    "            X_data.append(img_path)\n",
    "            y_data.append(angle)\n",
    "            \n",
    "            if load_side_camera_images_flag:\n",
    "                left_file_name = row[1].strip()\n",
    "                img_path_left = Image.open('./recording/' + left_file_name)\n",
    "                X_data.append(img_path_left)\n",
    "                y_data.append(angle + correction) \n",
    "                \n",
    "                right_file_name = row[2].strip()\n",
    "                img_path_right = Image.open('./recording/' + right_file_name)\n",
    "                X_data.append(img_path_right)\n",
    "                y_data.append(angle - correction)    \n",
    "                \n",
    "load_images() \n",
    "\n",
    "print('Data Samples shape:', X_data.shape, y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data distribution\n",
    "#Large number of data points for 3 valuse, and smaller number for rest of data points\n",
    "from collections import Counter\n",
    "\n",
    "plt.hist(y_data, 100)\n",
    "plt.show()\n",
    "\n",
    "counts = Counter(y_data)\n",
    "print (counts.most_common(3) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flip(img,angle):\n",
    "    return cv2.flip(img,1),-angle\n",
    "\n",
    "def shift(img,angle):\n",
    "    # this will shift image horizontally and vertically and add a small value--> same in Project2\n",
    "    rows,cols,ch = img.shape\n",
    "    range_tr = 100\n",
    "    dx = range_tr * np.random.uniform() - range_tr/2\n",
    "    dy = 40 * np.random.uniform()-40/2\n",
    "    M = np.float32([[1, 0, dx], [0, 1, dy]])\n",
    "    img = cv2.warpAffine(img, M, (cols, rows))\n",
    "    angle += dx/range_tr*2*.2\n",
    "    return img, angle\n",
    "\n",
    "def brightness(img, angle):\n",
    "    if np.random.uniform()>0.5:\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        deltaBright = .5 + np.random.uniform() * 0.5\n",
    "        hsv[:, :, 2] = np.around(hsv[:, :, 2] * deltaBright)\n",
    "        img = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "    return img, angle\n",
    "\n",
    "def augment(img, angel):\n",
    "    img, angle = flip(img, angle)\n",
    "    img, angle = shift(img, angle)    \n",
    "    img, angle = brightness(img, angle)                    \n",
    "    return img, angle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example of Images\n",
    "index = 2000\n",
    "\n",
    "# Original Image\n",
    "img = cv2.imread(X_data[index])\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "plt.title('Steering Angle: '+ str(angles[index]))\n",
    "plt.savefig('./original_image.png')\n",
    "plt.show()\n",
    "\n",
    "# Augment Image\n",
    "new_img,new_angle = augment(img,angles[index])\n",
    "plt.imshow(new_img)\n",
    "plt.title('Steering Angle: '+ str(new_angle))\n",
    "plt.savefig('./image_augment.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_training_data(image_paths, angles, batch_size=128, validation_flag=False):\n",
    "    image_paths, angles = shuffle(image_paths, angles)\n",
    "    while True:       \n",
    "        for offset in range(0,len(angles),batch_size):\n",
    "            batch_samples_paths = image_paths[offset:offset+batch_size]\n",
    "            batch_samples_angles = angles[offset:offset+batch_size]\n",
    "            images_gen,angles_gen = ([],[])\n",
    "            for i in range(len(batch_samples_paths)):\n",
    "                img = cv2.imread(batch_samples_paths[i])\n",
    "                angle = batch_samples_angles[i]\n",
    "                img = augment(img)\n",
    "                if not validation_flag:\n",
    "                    img, angle = shift_image(img, angle)\n",
    "                images_gen.append(img)\n",
    "                angles_gen.append(angle)\n",
    "            yield (np.array(images_gen), np.array(angles_gen))\n",
    "            image_paths, angles = shuffle(image_paths, angles)\n",
    "\n",
    "# use batch Normalization and L2 Regularizer to prevent overfitting, instead of dropout.\n",
    "def train_model(image_paths):\n",
    "    image_paths_train, image_paths_valid, angles_train, angles_valid = \n",
    "        train_test_split(image_paths, angles, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    # Normalize\n",
    "    model.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape=(160,320,3)))\n",
    "    model.add(Cropping2D(cropping=((70,25),(0,0))))\n",
    "\n",
    "    # Add three 5x5 convolution layers (output depth 24, 36, and 48), each with 2x2 stride\n",
    "    model.add(Convolution2D(24, 5, 5, subsample=(2, 2), border_mode='valid', W_regularizer=l2(0.001)))\n",
    "    model.add(ELU())\n",
    "#     model.add(BatchNormalization(axis=-1))\n",
    "    \n",
    "    model.add(Convolution2D(36, 5, 5, subsample=(2, 2), border_mode='valid', W_regularizer=l2(0.001)))\n",
    "    model.add(ELU())\n",
    "    model.add(Convolution2D(48, 5, 5, subsample=(2, 2), border_mode='valid', W_regularizer=l2(0.001)))\n",
    "    model.add(ELU())\n",
    "\n",
    "    #model.add(Dropout(0.50))\n",
    "    \n",
    "    # Add two 3x3 convolution layers (output depth 64, and 64)\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode='valid', W_regularizer=l2(0.001)))\n",
    "    model.add(ELU())\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode='valid', W_regularizer=l2(0.001)))\n",
    "    model.add(ELU())\n",
    "\n",
    "    # Add a flatten layer\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Add three fully connected layers (depth 100, 50, 10), tanh activation (and dropouts)\n",
    "    model.add(Dense(100, W_regularizer=l2(0.001)))\n",
    "    model.add(ELU())\n",
    "    #model.add(Dropout(0.50))\n",
    "    model.add(Dense(50, W_regularizer=l2(0.001)))\n",
    "    model.add(ELU())\n",
    "    #model.add(Dropout(0.50))\n",
    "    model.add(Dense(10, W_regularizer=l2(0.001)))\n",
    "    model.add(ELU())\n",
    "    #model.add(Dropout(0.50))\n",
    "\n",
    "    # Add a fully connected output layer\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile and train the model\n",
    "    model.compile(optimizer=Adam(lr=1e-4), loss='mse')\n",
    "\n",
    "    print(model.summary())\n",
    "    # initialize generators\n",
    "    train_gen = generate_training_data(image_paths_train, angles_train, validation_flag=False, batch_size=120)\n",
    "    val_gen = generate_training_data(image_paths_valid, angles_valid, validation_flag=True, batch_size=120)\n",
    "\n",
    "    checkpoint = ModelCheckpoint(filepath='model.h5', monitor='val_loss', verbose=2, save_best_only=True)\n",
    "    history = model.fit_generator(train_gen, validation_data=val_gen, \n",
    "                                  nb_val_samples=image_paths_test.shape[0], \n",
    "                                  samples_per_epoch=image_paths_train.shape[0],\n",
    "                                  nb_epoch=20, verbose=2, callbacks=[checkpoint])\n",
    "\n",
    "    # Save model data\n",
    "    model.save('model.h5')\n",
    "    print('Model Saved..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('Mean Squared Error Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'Validation'], loc='upper right')\n",
    "plt.show()\n",
    "fig.savefig('./train_val_acc.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
